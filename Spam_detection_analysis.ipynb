{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam detection analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdDe81oczovx"
      },
      "source": [
        "#$$ \\textbf{SPAM DETECTION ANALYSIS USING NLP} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPCihQfbJiwM",
        "outputId": "54c7fb3e-93e8-48dd-8c81-b5fe6832e0fe"
      },
      "source": [
        "# import modules\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyxfFjhXTrN5"
      },
      "source": [
        "# loading the dataset \n",
        "df=pd.read_csv('spam.csv', encoding='latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "xzNA9AgPUFd8",
        "outputId": "0f4df0de-806b-4a95-c847-d6c4bb397c5e"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        v1  ... Unnamed: 4\n",
              "0      ham  ...        NaN\n",
              "1      ham  ...        NaN\n",
              "2     spam  ...        NaN\n",
              "3      ham  ...        NaN\n",
              "4      ham  ...        NaN\n",
              "...    ...  ...        ...\n",
              "5567  spam  ...        NaN\n",
              "5568   ham  ...        NaN\n",
              "5569   ham  ...        NaN\n",
              "5570   ham  ...        NaN\n",
              "5571   ham  ...        NaN\n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMc7xRBzVjRm"
      },
      "source": [
        "$$ \\textbf{since apart from the first two columns all the columns contains the null values only and hence we take only the first two columns} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kzqJR69VfSC"
      },
      "source": [
        "df = df[['v2','v1']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f36mS7WCWKEe"
      },
      "source": [
        "$$ \\textbf{ changing the column name as it is bit vague} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJqkYI1xWAJx",
        "outputId": "19406c71-686f-493b-9ab2-a8c3ce678249"
      },
      "source": [
        "df.rename(columns={'v2':'messages','v1':'label'}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HC5etT2jZdwT",
        "outputId": "898a9e74-dd17-4477-d913-2b1edd359bf1"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>messages</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            messages label\n",
              "0  Go until jurong point, crazy.. Available only ...   ham\n",
              "1                      Ok lar... Joking wif u oni...   ham\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam\n",
              "3  U dun say so early hor... U c already then say...   ham\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLTmw-TTW1MO"
      },
      "source": [
        "$$ \\textbf{ DATA PREPROCESSING } $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N65YQ2ppWi-e",
        "outputId": "8ee5dc4d-e7fd-4710-dc67-24080aab1d12"
      },
      "source": [
        "df.isnull().sum() # checking for the null value "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "messages    0\n",
              "label       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcX6b3GXKml"
      },
      "source": [
        "No null values in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q64eOlfJXFFT"
      },
      "source": [
        "Stopwords= set(stopwords.words('english'))\n",
        "def text_clean (text):\n",
        "  text= text.lower()  # converting all the alphabets in the lowercase\n",
        "  text= re.sub(r'[^0-9a-zA-Z]',' ',text) # removing the special characters\n",
        "  text=re.sub(r'\\s+',' ',text)  # removing extra spaces\n",
        "  text=\" \".join(word for word in text.split() if word not in Stopwords)   # remove stopwords\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "BuWXM77RY7BO",
        "outputId": "dc74430c-a4cc-4c50-a15c-6d15f5ee04a1"
      },
      "source": [
        "# clean the message\n",
        "df['clean_text']=df['messages'].apply(text_clean)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>messages</th>\n",
              "      <th>label</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>nah think goes usf lives around though</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            messages  ...                                         clean_text\n",
              "0  Go until jurong point, crazy.. Available only ...  ...  go jurong point crazy available bugis n great ...\n",
              "1                      Ok lar... Joking wif u oni...  ...                            ok lar joking wif u oni\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  ...  free entry 2 wkly comp win fa cup final tkts 2...\n",
              "3  U dun say so early hor... U c already then say...  ...                u dun say early hor u c already say\n",
              "4  Nah I don't think he goes to usf, he lives aro...  ...             nah think goes usf lives around though\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCjlr3SwbHdw"
      },
      "source": [
        "$$ \\textbf{INPUT SPLIT} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXH4bdaJaqh4"
      },
      "source": [
        "x=df[\"clean_text\"]\n",
        "y=df[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmi78GL5bs-Q"
      },
      "source": [
        "$$ \\textbf{MODEL TRAINING} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvcjm1PabsMm"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import classification_report\n",
        "def clasification(model , x, y):\n",
        "  # TEST AND TRAIN DATA SPLIT\n",
        "   X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.3, random_state=42, shuffle=True, stratify=y)\n",
        "   # model training\n",
        "   pipeline_model = Pipeline([('vector',CountVectorizer()),('tfidf',TfidfTransformer()),('CLF',model)])\n",
        "   pipeline_model.fit(X_train, Y_train)\n",
        "   print(\"accuracy\", pipeline_model.score(X_test,Y_test)*100)\n",
        "   Y_pred = pipeline_model.predict(X_test)\n",
        "   print(classification_report(Y_test,Y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-XlMp9E0MPi"
      },
      "source": [
        "$$ \\textbf{ USING LOGISTICSREGRESSION} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re6cpNSibnux",
        "outputId": "21f48821-f7ce-4f11-baa1-531d5eafb4b5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "clasification(model, x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 96.5909090909091\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1448\n",
            "        spam       0.99      0.75      0.86       224\n",
            "\n",
            "    accuracy                           0.97      1672\n",
            "   macro avg       0.98      0.88      0.92      1672\n",
            "weighted avg       0.97      0.97      0.96      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo3L53Um0LgX"
      },
      "source": [
        "$$ \\textbf{ USING MULTINOMIAL-NB} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecEkNYLWhRBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6615c3f0-d3ee-4efb-cdf3-87772d190f8d"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model= MultinomialNB()\n",
        "clasification(model,x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 96.65071770334929\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98      1448\n",
            "        spam       1.00      0.75      0.86       224\n",
            "\n",
            "    accuracy                           0.97      1672\n",
            "   macro avg       0.98      0.88      0.92      1672\n",
            "weighted avg       0.97      0.97      0.96      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H53KVSQA0C1t"
      },
      "source": [
        "$$ \\textbf{ USING SUPPORT VECTOR MACHINE } $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHq4WYbPycf-",
        "outputId": "a84a9aca-ff44-4bea-dccb-a1fe6a6064a1"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "model=SVC(C=3)\n",
        "clasification(model,x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 98.38516746411483\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.98      1.00      0.99      1448\n",
            "        spam       1.00      0.88      0.94       224\n",
            "\n",
            "    accuracy                           0.98      1672\n",
            "   macro avg       0.99      0.94      0.96      1672\n",
            "weighted avg       0.98      0.98      0.98      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRUp4Y_sz5To"
      },
      "source": [
        "$$ \\textbf{ USING RANDOMFOREST} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOGL2CbIyw1B",
        "outputId": "927e4a79-5c37-4e4a-bcad-3f6f38ae76b3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "model = RandomForestClassifier()\n",
        "clasification(model,x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy 97.60765550239235\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.99      1448\n",
            "        spam       1.00      0.82      0.90       224\n",
            "\n",
            "    accuracy                           0.98      1672\n",
            "   macro avg       0.99      0.91      0.94      1672\n",
            "weighted avg       0.98      0.98      0.98      1672\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UmKcxSjzY8A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}